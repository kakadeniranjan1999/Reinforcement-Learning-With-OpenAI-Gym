600-135


random selection of action may be leads the agent to hole at the end of training.coz we can see consecutive goal reaches but at a point it goes to hole.
random action selection is also important else model can overfit. optimum use of random action selection is needed.
early gain of goal can also matter
random action is better and we need to have a increase min_epsilon for getting earlier accuracy in case of min_epsilon approach

put tags
FrozenLakeDQN-M1